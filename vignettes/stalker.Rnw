\documentclass[a4paper]{amsart}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{hyperref}
\newcommand{\strong}[1]{{\normalfont\fontseries{b}\selectfont #1}}
\let\pkg=\strong
\newcommand\code{\bgroup\@codex}
\def\@codex#1{{\normalfont\ttfamily\hyphenchar\font=-1 #1}\egroup}

\newcommand{\RN}{\mathbb{R}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\figsize}{7cm}
\newcommand{\sign}{\operatorname{sgn}}
%% \VignetteIndexEntry{Description of the stalker spline}
%% \VignetteEngine{knitr::knitr}
%% \VignetteDepends{plot3D}
\setlength{\textwidth}{\paperwidth}
\setlength{\textheight}{\paperheight}
\addtolength{\textwidth}{-3cm}
\addtolength{\textheight}{-4cm}
\calclayout


\title{The stalker spline}

\author{Simen Gaure}
\address{Ragnar Frisch Centre for Economic Research, Oslo, Norway}
\date{July 28, 2018}

\begin{document}
\setkeys{Gin}{width=0.6\textwidth }
\begin{abstract}
  The idea behind the stalker spline in package \pkg{chebpol} is
  outlined.  It is designed as a one-dimensional interpolation to be almost 
  shape preserving in the sense
  that it attempts to honour monotonocity properties and local extreme
  points in the data, though not entirely. There is no fancy theory
  behind, but it served a purpose for the author, and here it is. The
  near monotonicity is achieved by somewhat non-traditional means, by
  sacrificing analyticity, and in a corner case even
  differentiability.  That is, the derivative is not well behaved.
  The name comes from the fact that it follows the data frighteningly
  close, though it sometimes seems stupid with little foresight. \pkg{chebpol}
  contains higher dimensional versions too, but they could as well be called \emph{wet paper spline}.  The
  interpolation isn't a proper spline, since it is not a
  polynomial. We also obtain a limit in intuitive geometric terms on
  how large the overshoot can be. The stalker spline can be used when
  a little more smoothness than multilinear is required.
\end{abstract}
\maketitle
\section{Introduction}
The multilinear interpolation in \pkg{chebpol} is easy to understand. 
We have some points on the \(x\)-axis.
At every point we have a value, and we just draw straight lines between the ``knots'':

<<fig.dim=c(4,4),echo=FALSE>>=
library(chebpol)
set.seed(42)
N <- 10
pts <- as.numeric(seq(1,N))
val <- runif(N)
val[5] <- val[4]
val[6] <- val[6] - 0.3
val[7] <- val[8] + 0.00001
s <- seq(1,N,len=1000)
plot(pts,val,pch=20,xlab='x',ylab='y')
ml <- ipol(val,grid=pts,method='multi')
lines(s,ml(s))
@ 

There is another way to think about this, we can imagine that at each
knot \(i\) there lives a function \(f_i(x)\). Whenever we are between
two knots, the interpolated value is a convex combination of the two
functions at each side. Say we are in \(x=3.3\). We should have a part
of \(f_3(3.3)\), and a part of \(f_4(3.3)\), the value should be
\(0.7f_3(3.3) + 0.3f_4(3.3)\), or more generally for \(3 \leq x \leq
4\), \(t f_3(x) + (1-t)f_4(x)\) where \(0 \leq t=4-x \leq 1\).  In the
multilinear case, all the functions are constant, and equal to the
value in the point where it lives.

<<out.width='0.5\\linewidth', echo=FALSE>>=
plot(pts,val,pch=20,xlab='x',ylab='y')
for(i in seq_along(pts)) {
    lines(pts[i]+c(-1,1),c(val[i],val[i]))
}
@ 

When we make a convex combination of two constant values \(v_i\) and
\(v_{i+1}\), we obtain a straight line: \(t v_i + (1-t) v_{i+1}\).
This linear interpolation is faithful to the data in the sense that
it honours local extrema as well as monotonicity.

In the stalker spline we replace these constant functions with non-constant
functions. I.e. the function \(f_i(x)\) should not be constant, but pass
through the 3 knots \(i-1, i\) and \(i+1\). A classical method is to
let \(f_i\) be the unique quadratic which passes through the three knots. 

<<fig.dim=c(5,5), echo=FALSE>>=
plot(pts,val,pch=20,xlab='x',ylab='y',ylim=c(0,1.1))
for(i in seq_along(pts)[c(-1,-length(pts))]) {
    a <- val[i]
    b <- (val[i+1] - val[i-1])/2
    c <- val[i+1]-a-b
    ss <- seq(-1,1,len=20)
    lines(ss+i,a+b*ss+c*ss^2,col=c('blue','green','red')[i%%3+1])
}
@ 

The interpolated value between two knots is still a convex combination
of the two functions living there. The result is that the interpolant between
any two points is a cubic, with a value between the two functions
living there.

In the random points
we have chosen, we have deliberately made the fourth and fifth points
equal. The 7th and 8th differ by only 0.00001. 
This accentuates a phenomenon which in some cases can be
a problem, no polynomial except for the constant
can be constant on an interval. There is ``overshoot'' between knots
4 and 5. Indeed, many of the functions overshoot, like between 7 
and 8.


The idea behind the stalker spline is to reduce the overshoot, this is
achieved by ensuring that if the knots \(i-1, i\) and \(i+1\) are
monotonic (either increasing or decreasing), then the function
\(f_i(x)\) will also be monotonic.  Other splines, like the Fritsch-Carlson spline in
\code{splinefun(...,method='monoH.FC')} also does something similar, though with proper
polynomial spline.
We achieve this by non-traditionally using a
fractional degree, i.e. a function of the form \(a + bx + c|x|^r\),
with \(1\leq r \leq 2\). In this note we call these functions defined by
three points and a monotonicity constraint, \emph{basis functions}. They
are not basis functions in the vector space sense used in the spline literature; they are
not glued together by scalar weights, but by linear functions.

\section{The stalker spline}
To simplify, we consider a basis function \(f(x)\) on the
interval \([-1,1]\). We have its function values in the three knots
\(f(-1) = v_-\), \(f(0) = v_0\), and \(f(1) = v_+\). We assume

\begin{equation}
f(x) = a + bx + c|x|^r.
\end{equation}
Inserting our three points, we obtain three equations with three unknowns:
\begin{equation}\label{cdef}
\begin{aligned}
&a - b + c &= v_-,\\
&a &= v_0,\\
&a + b + c &= v_+.\\
\end{aligned}
\end{equation}

The solution is 
\begin{equation}\label{cvals}
\begin{aligned}
a &= v_0,\\
b &= \frac12 (v_+-v_-),\\
c &= \frac12 (v_+ + v_-) - v_0.\\
\end{aligned}
\end{equation}

These coefficients will work with any \(r\). Typically we will pick
\(r = 2\), but this may destroy monotonicity.
The three knots are monotonic (either increasing or decreasing)
whenever \(|c| < |b|\). This can be seen from equation~\eqref{cdef}.
Monotonicity occurs when \(v_+ - v_0 = b+c\) has the same sign 
as \(v_0 - v_- = b-c\), which is precisely when \(|c| < |b|\).

If this is the case we will use monotonicity
to find a suitable \(r\).  To be specific, we have
\begin{equation}\label{deriv}
f'(x) = b + cr|x|^{r-1}\sign(x),
\end{equation}
where \(\sign(x)\) is the sign function.  We have a critical point
\(f'(x) = 0\) for \(|x|^{r-1}\sign(x) = -b/(cr)\). This equation has a
solution in \(-1 < x < 1\) if \(|b| < r|c|\).  We pick an \(r\) so
that the critical point disappears from the interior.  More
specifically, if \(r=2\) results in non-monotonicity, i.e.\ if
\(|b| < 2|c|\), we pick the largest \(r\) which will make \(f(x)\)
monotonic. That is, \(r = |b/c| < 2\), this will relegate the
critical point to one of the end points.

The same exercise with a non-uniform grid results in a non-linear
equation in \(r\) which is solved numerically by \pkg{chebpol}.

There are some special cases.  What if \(c=0\)? This
only happens when the knots are collinear, i.e. on a straight line,
but then \(r\) is irrelevant,
so we do not need to compute it.
What about the corner case \(|b|=|c|\)? This happens if \(v_0\) equals
either \(v_-\) or \(v_+\), i.e. if we have a horizontal region. In
this special case, \(r=1\), and we have a non-differentiable 
\(f(x) = a + b(x \pm |x|)\), which is constant on one side of 0 and linear
on the other.

At the outset, we only need to adjust \(r\) away from 2 when there is
monotonicity which is violated by a quadratic, i.e. 
when \(|c| < |b| < 2|c|\). If we stick strictly to this idea,
it means that as soon as \(|b| < |c|\), we will change the degree
\(r\) from 1 to 2 in a jump. That is, for \(|b|=|c|\) we have a
constant/linear function, but if \(|b|\) decreases ever so little,
\(|b| = |c| - \epsilon\), we suddenly shift to a quadratic which may
have considerable overshoot.  To make this transition smoother, we (somewhat
arbitrarily) set
\(r = |c/b|\) whenever \(|c/2| < |b| < |c|\), i.e. we gradually creep
back to \(r=2\).

In figure~\ref{fig:basis} is a plot of some of the functions for the case \(v_-=0\), \(v_+=1\),
with varying \(v_0\) (the black dots).

<<basis,echo=FALSE,fig.dim=c(7,5), fig.align='center', fig.cap='"Basis functions"'>>=
s <- seq(-1,1,len=100)
plot(range(s),c(-0.7,1.7),pch='',xlab='x',ylab='y')
v0 <- seq(-0.7,1.7,len=41)
f0spline <- function(f0) {
  b <- 0.5
  c <- 0.5*(1-2*f0)
  if(b < 2*abs(c) && abs(c) < b)
    r <- abs(b/c)
  else if (abs(c) < 2*b && abs(b) < abs(c))
    r <- abs(c/b)
  else
    r <- 2
  f0 + b*s + c*abs(s)^r
}
for(f0 in v0) {
  col <- if( (f0 < 0.75 && f0 > 0.25) || (f0 > 1.5 || f0 < -0.5) ) 
           'darkblue' 
         else if(f0 < 1 && f0 > 0)
           'blue'
         else
           'lightblue'
  lines(s,f0spline(f0),col=col)
  points(0,f0,pch=20)
}
# illustrate overshoot
clip(0,0.5,-2,2)
abline(h=-0.7,lty=2)
clip(-0.5/(2*(0.5+0.7)),0.5,-2,2)
abline(h=-0.7-0.25/(4*(0.5+0.7)), lty=2)
clip(-2,2,-2,2)
text(x=0.7,y=-0.63,'} overshoot',pos=1)
@ 

The dark blue curves are quadratic. The blue curves are monotonic, but
with lowered degree. The light blue curves are non-monotonic with
lowered degree.  Every function except for the two obvious ones are
continuously differentiable, but not twice differentiable in \(0\).
If we let \(|v_0|\) grow further, the function will stay quadratic,
and the extreme point and the overshoot will converge to 0. Ideally,
the non-monotonic curves should have an extreme point in \(x=0\),
i.e.\ no overshoot, but that is impossible with this function form.

If either \(v_-\) or \(v_+\) grows, \(|b/c|\) converges to 1, so
we will converge to the non-differentiable case. However, there is a
problem which becomes pressing when trying to use the stalker spline
in two or more dimensions.  If, as in figure~\ref{fig:failure}, \(v_-\) moves, the curve for
\(x < 0\) moves down, but the curve for \(x>0\) moves up or down
depending on whether the degree changes or not. 
This behaviour creates problems e.g.\ for surfaces with torsion, as we shall see later.

<<failure,echo=FALSE,fig.dim=c(7,5), fig.align='center', fig.cap='"Basis functions"'>>=
s <- seq(-1,1,len=100)
vseq <- seq(-1,1,len=41)
rr <- m <- v <- list()
for(i in seq_along(vseq)) {
  #  double iD = 1.0/(dmin*pow(dplus,r) + pow(dmin,r)*dplus);
  #  double b = (vplus*pow(dmin,r) - vmin*pow(dplus,r))*iD;
  #  double c = (vplus*dmin + vmin*dplus)*iD;
  b <- 0.5*(1-vseq[[i]])
  c <- 0.5*(1+vseq[[i]])
  if(b < 2*abs(c) && abs(c) <= b)
    r <- abs(b/c)
  else if (abs(c) < 2*b && abs(b) < abs(c))
    r <- abs(c/b)
  else
    r <- 2

  rr[[i]] <- r
  m[[i]] <- abs(c) <= b
  v[[i]] <- b*s + c*abs(s)^r
}
plot(range(s),do.call(range,c(v,list(finite=TRUE))),pch='',xlab='x',ylab='y')
for(i in seq_along(v)) {
  cl <- if(identical(rr[[i]],2)) 'darkblue' else if(isTRUE(m[[i]])) 'blue' else 'lightblue'
  lines(s,v[[i]],col=cl)
}
points(rep(-1,length(vseq)),vseq,pch=20)
@ 

The stalker spline also contains hyperbolic functions of the type
\(a + bx +\frac{d}{1+cx}\) which are guaranteed to honour both monotonicity
and local extrema.
Again we have four parameters and three points. For monotonic
points we use monotonocity as a fourth constraint, or more precisely we let \(b=0\). 
For non-monotonic points, we use
that the middle point should be a local extremum. Thus, the hyperbolic stalker respects
both monotonicity and local extrema, but still at the cost of non-differentiability
in the case of completely flat regions. In another special case, it reduces to a parabola.
The hyperbolic stalker is specified as \code{ipol(..., method='hstalker')}.

\section{Overshoot and blending}
To sum up, the function passing through \((-1,v_-)\), \((0,v_0)\) and
\((1,v_+)\) is 
\begin{equation}
f(x) = a + bx + c|x|^r.
  \end{equation}
The coefficients \(a\), \(b\), and \(c\) are as in~\eqref{cvals}. For \(c\neq 0\) the exponent \(r\) is 
chosen as follows:
\begin{equation}
r = \begin{cases}
 |b/c| &\text{for \(|c| \leq |b| < 2|c|\)},\\
 |c/b| & \text{for \(|b| < |c| < 2|b|\)},\\
 2 & \text{otherwise}.
\end{cases}
\end{equation}

It is clear that \(1 \leq r \leq 2\).
The functions with \(1 < r \leq 2\) are everywhere
differentiable, but for \(r < 2\) the second derivative is unbounded near 0, so
the graph may turn arbitrarily abruptly in the knots.

We define the overshoot as 0 for monotonic knots, and as \(|v_0 - f(x_0)|\) where
\(x_0\) is the critical point of the function: \(f'(x_0) = 0\).
From equation~\eqref{deriv} we have by elementary calculus \(x_0 = -\sign(bc)|b/(rc)|^{1/(r-1)}\).  
If \(|b| >= 2|c|\) then \(x_0 \notin (-1,1)\), hence the min/max
occurs in an end point, in which case it is not an overshoot.  
We look at the case \(|b| < r|c|\).

For \(r=2\) we must by definition have \(|c| \geq 2|b|\).
We have \(x_0 = -b/(2c)\). The function value in \(- b/(2c)\) is
\(a-b^2/(4c)\), the vertical distance from the point \(v_0=a\) is
\(d = |b^2/(4c)| \leq |b|/8\). Now, \(|b|\) is half the distance between
\(v_+\) and \(v_-\), so the overshoot will always be smaller than
\(|v_+ - v_-|/16\) for \(r=2\).

For \(r < 2\), \(r\) is either equal to
\(|b/c|\), in which case there is no overshoot, or \(r=|c/b|\) when
\(|c/2| < |b| < |c|\). We have \(x_0 = -\sign(bc) |b/(rc)|^{1/(r-1)}  = 
-\sign(bc)r^{2/(1-r)}.\)

The function value in the extreme point \(x_0\) is then
\(a - |b| \sign(c) r^{2/(1-r)} +  cr^{2r/(1-r)}\). The distance to \(v_0=a\) is
\(d_r = \left|  |c| r^{2r/(1-r)} - |b| r^{2/(1-r)}  \right| =
|b| \left| r^{(1+r)/(1-r)} - r^{2/(1-r)}\right|\).
Again, it is easy to show by elementary calculus that \(d_r\) is increasing in \(r\),
so \(d_r  \leq |b|/8\).

We can prove more. If we have \(|b| < |c|\) it means that \(v_0\) is the smallest
or the largest of the three knots. To simplify we assume that \(v_0 < v_- < v_+\), i.e. that
\(0 < b < c < 2b\). The situation is symmetric with the direction reversed.
We have that \(c-b = v_- - v_0\), the amount that
the middle knot is below the next lowest knot. We also have \(c-b = b(r-1)\).
If we compute the overshoot as a fraction of this ``knot overshoot'': \(d_r/(c-b) = d_r/(b(r-1))\), again
we get \(d_r/(v_- - v_0) =| r^{(1+r)/(1-r)} - r^{2/(1-r)} |/(r-1) \leq e^{-2} \approx 0.135\). 

In short, the overshoot is always less than 14\% of the vertical distance from the lowest/highest knot
to the next lowest/highest knot.

\section{Blending and degree}
There is a basis function in every knot, so we glue the functions
\(f_1\) and \(f_2\) together as a convex combination \(tf_1(x) +
(1-t)f_2(x-1)\) (\(x-1\) is the normalized coordinate for \(f_2\),
the basis function in the knot \(x_+\)). We use a linear blender,
\(t = 1 - x\).  Alternatively we could modify the \(t\) with a sigmoid blender like
\(t\in [0,1/2] \mapsto \exp(2-1/t)/2\) and \(t\in (1/2,1] \mapsto 1-\exp(2-1/(1-t))/2.\)
A cubic blender is also available. 
These can be selected by the argument \code{blend="linear"}, \code{blend="sigmoid"}, or
\code{blend="cubic"} to the
stalker interpolant. 
The three blending functions are shown in figure~\ref{fig:blending}.

<<blending, fig.dim=c(4,4),fig.cap='Blending functions'>>=
sigmoid <- function(t) ifelse(t<0.5, 0.5*exp(2-1/t), 1-0.5*exp(2-1/(1-t)))
cubic <- function(t) -2*t^3 + 3*t^2
linear <- function(t) t
s <- seq(0,1,length=100)
plot(s,sigmoid(s),typ='l',ylab='y')
lines(s,linear(s), col='blue')
lines(s,cubic(s), col='green')
legend('topleft',legend=c('sigmoid','linear','cubic'),fill=c('black','blue','green'))
@ 

The interpolant can be given a \code{"degree"} argument, this
can be a vector, a fixed degree for each dimension. 

In more than one dimension, torsion can be a problem for stability. It can create
striping artefacts. This can be alleviated by having constant degree (different from \code{NA}),
except possibly for the first dimension. We'll see an example later.


\section{Multidimensional hyperbolic stalker}
We now consider the generalization to higher dimensions, specifically \(\RN^n\).
We have a Cartesian product grid, and in every grid point there
should live a function. We will try to honor monotonicity and extreme points \emph{along
the axes}. We consider the function living in the point \((0,\ldots,0)\). 
The grids may be different in each dimension, but we call the three grid
points along dimension \(i\): \(k_i^-\), \(0\), and \(k_i^+\). That is, we have
\(k_i^- < 0 < k_i^+\). The corresponding function
values (with all arguments in other dimensions equal to 0) are \(v_i^-\),\(0\), and \(v_i^+\).

The function form we take to interpolate is (with \(x=(x_1,x_2,\ldots,x_n)\))
\begin{equation}\label{funcform}
f(x) = a + \sum_{i=1}^n b_i x_i + \sum_{i=1}^n \frac{d_i}{1+c_ix_i}
\end{equation}
We will drop the \(n\) from the sums, as this simplifies the formulas.
The function value \(f(0) = 0\) gives us an equation
\begin{equation}\label{zeroval}
a + \sum_i d_i = 0.
\end{equation}
For each \(i\) we also have equations for the two other grid points \(k_i^-\) and \(k_i^+\),
\begin{equation}
  \begin{aligned}
    v_i^+ &=a + b_i k_i^+ + \frac{d_i}{1+c_i k_i^+} + \sum_{j\neq i} d_j,\\
    v_i^- &=a + b_i k_i^- + \frac{d_i}{1+c_i k_i^-} + \sum_{j\neq i} d_j.\\
  \end{aligned}
\end{equation}

We introduce the simplifying notation \(D_i = \sum_{j\neq i} d_j\), and multiply the
equations by the denominator occuring in them to obtain:
\begin{equation}
  \begin{aligned}
    v_i^++ v_i^+ c_i k_i^+ &= a + ac_i k_i^+ +  b_i k_i^+ + b_i k_i^+ c_i k_i^+ +d_i+ D_i + c_i k_i^+ D_i,\\
    v_i^-+ v_i^- c_i k_i^- &= a + ac_i k_i^- +  b_i k_i^- + b_i k_i^- c_i k_i^- +d_i+ D_i + c_i k_i^- D_i.\\
  \end{aligned}
\end{equation}
Noting that \(a + d_i + D_i = 0\), we can simplify further.
\begin{equation}
  \begin{aligned}
    v_i^++ v_i^+ c_i k_i^+ &= ac_i k_i^+ +  b_i k_i^+ + b_i k_i^+ c_i k_i^+  + c_i k_i^+ D_i,\\
    v_i^-+ v_i^- c_i k_i^- &= ac_i k_i^- +  b_i k_i^- + b_i k_i^- c_i k_i^-  + c_i k_i^- D_i.\\
  \end{aligned}
\end{equation}
These can be simplified further by the same equation in the form \(c_i k_i^+ (a + D_i) = -c_i k_i^+ d_i\):
\begin{equation}\label{dimequations}
  \begin{aligned}
    v_i^++ v_i^+ c_i k_i^+ &= b_i k_i^+ + b_i k_i^+ c_i k_i^+  -c_i k_i^+ d_i,\\
    v_i^-+ v_i^- c_i k_i^- &= b_i k_i^- + b_i k_i^- c_i k_i^-  -c_i k_i^- d_i.\\
  \end{aligned}
\end{equation}

\subsection{Monotonicity}
We now look at monotonocity. Given the three values \(v_i^-,0\), and \(v_i^+\), they are either monotonic
or \(0\) is a local extremum. If they are monotonic we must ensure that our function is monotonic as
well, i.e. that the derivative along this dimension is different from zero.  We have the
derivative along dimension \(i\):
\begin{equation}
  f_i(x) = b_i - \frac{c_i d_i}{(1+c_i x_i)^2}.
\end{equation}
One way to ensure it is nonzero is to choose \(b_i=0\).
This is what we do for monotonic points.
The equations~\eqref{dimequations} then simplify to:
\begin{equation}
  \begin{aligned}
    v_i^++ v_i^+ c_i k_i^+ &=  -c_i k_i^+ d_i,\\
    v_i^-+ v_i^- c_i k_i^- &=  -c_i k_i^- d_i.\\
  \end{aligned}
\end{equation}
These can be solved for \(c_i\) and \(d_i\) to yield,
\begin{equation}\label{monopars}
  \begin{aligned}
    b_i &= 0,\\
    c_i &= -\frac{k_i^- v_i^+ - k_i^+ v_i^-}{k_i^-  k_i^+ (v_i^+ - v_i^-)},\\
    d_i &= -\frac{v_i^+ v_i^- (k_i^- - k_i^+)}{k_i^- v_i^+ - k_i^+ v_i^-}.\\
  \end{aligned}
\end{equation}

\subsection{Non-monotonicity}
When the three points are non-monotonic, the middle one is an extreme point, i.e.
\(f_i(0) = 0\). This yields the equation,
\begin{equation}
  b_i = c_i d_i.
\end{equation}
Inserting this in equations~\eqref{dimequations} yields,
\begin{equation}
  \begin{aligned}
    v_i^++ v_i^+ c_i k_i^+ &= c_i d_i k_i^+ + c_i d_i k_i^+ c_i k_i^+  -c_i k_i^+ d_i,\\
    v_i^-+ v_i^- c_i k_i^- &= c_i d_i k_i^- + c_i d_i k_i^- c_i k_i^-  -c_i k_i^- d_i.\\
  \end{aligned}
\end{equation}
These immediately simplifies to,
\begin{equation}
  \begin{aligned}
    v_i^++ v_i^+ c_i k_i^+ &= c_i d_i k_i^+ c_i k_i^+,\\
    v_i^-+ v_i^- c_i k_i^- &= c_i d_i k_i^- c_i k_i^-.\\
  \end{aligned}
\end{equation}
The solution is,
\begin{equation}\label{nmonopars}
  \begin{aligned}
    b_i &= \frac{v_i^+ v_i^- (k_i^--k_i^+)}{(k_i^-)^2 v_i^+-(k_i^+)^2 v_i^-},\\
    c_i &= -\frac{(k_i^-)^2 v_i^+-(k_i^+)^2 v_i^-}{k_i^- k_i^+ (k_i^- v_i^+-k_i^+ v_i^-)},\\
    d_i &= -\frac{(k_i^- v_i^+-k_i^+ v_i^-) k_i^- v_i^+ v_i^- k_i^+ (k_i^--k_i^+)}{((k_i^-)^2 v_i^+-(k_i^+)^2 v_i^-)^2}\\
  \end{aligned}
\end{equation}
So, both for monotonic and non-monotonic triples we can find the constants
\(b_i,c_i\) and \(d_i\) from equations~\eqref{monopars} and~\eqref{nmonopars}.
From equation~\eqref{zeroval} we can then find \(a\),
and we have all the parameters in the definition of the function \(f\) in equation~\eqref{funcform}.

We can try this out on a simple example, on a grid \((-1,0,1)\) in two dimensions,
i.e. \(k_i^- = -1\) and \(k_i^+ = 1\).
We let \(w_1 = 1/2, v_1 = 1, w_2=-2, v_2 = 1\). I.e. non-monotonic in the
first dimension, monotonic in the second. We get the parameters:
\(b_1 = -2, c_1 = -1/3, d_1 = 6, b_2=0, c_2=1/3, d_2=-4, a=-2\). An illustration
of the function can be found in figure~\ref{fig:2dhyp}.

<<2dhyp,fig.dim=c(4,4),fig.cap='Hyperbolic 2d function',echo=FALSE>>=
a <- -2
b.1 <- -2; c.1 <- -1/3; d.1 <- 6
b.2 <- 0; c.2 <- 1/3; d.2 <- -4

f <- function(x) a + b.1*x[1] + b.2*x[2] + d.1/(1+c.1*x[1]) + d.2/(1+c.2*x[2])
g <- list(x=seq(-1,1,len=50), y=seq(-1,1,len=50))
light <- list(specular=0.2,ambient=0.0,diffuse=0.6)
plot3D::persp3D(g$x, g$y, evalongrid(f,grid=g), colvar=NULL, lighting=light,
        theta=45, ltheta=10, lphi=40, col='green')
plot3D::points3D(c(0,1,0,-1,0),c(0,0,1,0,-1),c(0,1,1,1/2,-2)+0.05,pch=20,add=TRUE,colvar=NULL)
@ 

\subsection{Special cases}
There are some special cases, corresponding to data which can not be fitted with
the function form in equation~\eqref{funcform}. More specifically, some of the
denominators in equations~\eqref{monopars} and~\eqref{nmonopars} can vanish. We take the
monotonic case first. Monotonicity means that \(v_i^-\) and \(v_i^+\) have opposite
signs, but what if they are equal? The formula for \(c_i\) breaks down.
But this is trivial, in this case we have a completely flat function with 
\(v_i^- = v_i^+ = 0\), and \(b_i = d_i = 0\), with \(c_i\) irrelevant.

The other special case in the monotonicity formulae is when \(k_i^- v_i^+ = k_i^+ v_i^-\).
In this case, the points are on a straight line with derivative \(v_i^+/k_i^+ = v_i^-/k_i^-\), we take
\(b_i = v_i^+/k_i^+\), \(c_i = d_i = 0\).

Then to the non-monotonic special cases.
The first case is when the formula for \(c_i\) breaks down, this is linearity and is defined
as monotonic and handled there.
The case where \(b_i\) and \(d_i\) are ill-defined is more complicated, it happens
when \((k_i^-)^2 v_i^+ = (k_i^+)^2 v_i^-\). The three points lie on a parabola with
its vertex in 0. We are unable to fit our function to these points, instead we
choose a parabola, i.e. \(\frac{v_i^+}{(k_i^+)^2} x_i^2\). For the purpose of computing
\(a\) from equation~\eqref{zeroval}, we use \(d_i = 0\).

\subsection{Blending}
Our functions are defined around each grid point in such a way that they
agree with the given values on a ``cross''. They do not agree in the corners. 
E.g. for two-dimensional data an \(f\) living in \((0,0)\) agree with the
given values in \((0,0), (0,1), (1,0), (0,-1)\) and \((-1,0)\), but not in
\((1,1), (1,-1), (-1,1)\) and \((-1,-1)\).

When interpolating a point, there is a function living in each corner around it,
but how should they be weighted?

The simplest method is to use the barycentric coordinates of our point, i.e. the
weight for a corner is the volume of the cube opposite the point. Alternatively,
these weights can be modified by some sigmoid function. An illustration can be found
in figure~\ref{fig:2dblending}. We have a point in \((0.3,0.4)\), there are functions
living in each corner, the black dots. The weight for the function in \((1,1)\) is the
area of the lower blue rectangle \(0.3 \times 0.4 = 0.12\).

<<2dblending,fig.dim=c(3,3), fig.cap='Blending',echo=FALSE>>=
#  par(mar=rep(0,4))
  plot(c(0,1,1,0),c(0,0,1,1),pch=20,xlab='',ylab='')
  points(0.3,0.4,col='blue')
  abline(v=0.3,h=0.4,col='blue',lty=2)
@


This will ensure continuity, but it will not ensure differentiability even in simple
examples, due to the fact that the function living in \((1,1)\) has a value in \((0,0)\)
which is different from the given value in \((0,0)\). Therefore, the hyperbolic
stalker is by default blended with a cubic.


\section{Examples}
In this section we compare the stalker spline to the 
\code{"natural"} and \code{"monoH.FC"} spline from \code{stats::splinefun}.
We also illustrate the hyperbolic stalker spline with a cubic blender. With
the hyperbolic stalker, the linear blender is not able to smooth out the pole
in the flat case, whereas the cubic is. The sigmoid blender will smooth out any 
non-essential singularity, but the resulting curve may not be very pleasant. Plotting
the derivative of these interpolants is not for the faint-hearted.

<<echo=FALSE,fig.dim=c(6,4)>>=
pts <- pts-min(pts)
pts <- pts/max(pts)
plot(pts,val,pch=20,xlab='x',ylab='y',ylim=c(0,1.1))
ns <- splinefun(pts,val,method='natural')
ms <- splinefun(pts,val,method='mono')
st <- ipol(val,grid=pts,method='stalker',k=NA)
hst <- ipol(val,grid=pts,method='hstalker')
s <- seq(0,1,len=1000)
lines(s,ns(s),col='blue')
lines(s,ms(s),col='green')
lines(s, st(s), col='magenta')
lines(s, hst(s),col='red')
legend('topright',legend=c('stalker','mono','natural','hyperbolic'),
       fill=c('magenta','green','blue','red'))
@ 

Note that both the stalker and the \code{"monoH.FC"} spline honours the
completely flat region between points 4 and 5, but between points 7
and 8 \code{"monoH.FC"} has considerable overshoot, even though the
points are very close. The reason is that point 8 is slightly lower
than point 7, so that points 7-10 are not monotonic, and then the
spline there abandons its monotonicity constraint entirely.  Mathematically,
the stalker spline is differentiable except in points 4 and 5, even though it
looks like a sharp corner in point 8 due to a very large second derivative.

We also illustrate the same splines on a monotonic set of points. If all the
knots are monotonic, the Fritsch-Carlson spline is superb, it ensures monotonicity
and differentiability. The stalker spline does not in case there are completely
flat regions, then differentiability is abandoned.

<<fig.dim=c(6,4),echo=FALSE>>=
val <- sort(val)
plot(pts,val,pch=20,xlab='x',ylab='y',ylim=c(0,1.1))
ns <- splinefun(pts,val,method='natural')
ms <- splinefun(pts,val,method='mono')
st <- ipol(val,grid=pts, method='stalker', k=NA)
hst <- ipol(val,grid=pts,method='hstalker')
s <- seq(0,1,len=1000)
lines(s,ns(s),col='blue')
lines(s,ms(s),col='green')
lines(s, st(s), col='magenta')
lines(s, hst(s), col='red')
legend('topleft',legend=c('stalker','mono','natural','hyperbolic'),
       fill=c('magenta','green','blue','red'))
@ 

An interesting case is when the knots are pairwise constant. The stalker spline
reduces to a linear interpolation. The knots below are not
exactly pairwise constant, they differ by \(10^{-16}\). This is sufficient
to make \code{"monoH.FC"} overshoot.

<<fig.dim=c(6,4),echo=FALSE>>=
val <- rep(runif(N/2),each=2) + c(0,1e-16)
plot(pts,val,pch=20,xlab='x',ylab='y',ylim=c(0,1.1))
ns <- splinefun(pts,val,method='natural')
ms <- splinefun(pts,val,method='mono')
st <- ipol(val,grid=pts, method='stalker',k=NA)
hst <- ipol(val,grid=pts,method='hstalker')
s <- seq(0,1,len=1000)
lines(s,ns(s),col='blue')
lines(s,ms(s),col='green')
lines(s, st(s), col='magenta')
lines(s, hst(s), col='red')
legend('topleft',legend=c('stalker','mono','natural','hyperbolic'),
       fill=c('magenta','green','blue','red'))
@ 

\section{Higher dimensions}
The stalker spline in higher dimension \(N\) is simplistic and problematic.
It works on a Cartesian grid.
When evaluating the stalker in an \(x\) between grid points, the stalker is evaluated
for the \(N-1\) first dimensions on two grid lines on each side of \(x\)
in dimension \(N\). On these four points in dimension \(N\), two basis functions
are found, evaluated and blended.  There is no guarantee that doing this
with the dimensions in another order will yield exactly the same result.

Everything comes at a price, the price for the stalker spline is that it does not
work very well in higher dimensions. The variable degree causes creasing artefacts.

The hyperbolic stalker (method='hstalker') is better at this.

We take a look at 2d-interpolation, first the Maungawhau volcano with
exaggerated height in figure~\ref{fig:volcano}. It is quite nice with the stalker interpolation.

<<volcano, fig.dim=c(4,4), fig.align='center', fig.pos='!ht', fig.cap='Maungawhau', out.width='.37\\linewidth', fig.ncol=2, fig.subcap=c('low resolution','multilinear','stalker','thin plate spline')>>=
data(volcano)
volc <- volcano[seq(1,nrow(volcano),3),seq(1,ncol(volcano),3)]/10 #low res volcano
grid <- list(x=as.numeric(seq_len(nrow(volc))), y=as.numeric(seq_len(ncol(volc))))
ph <- ipol(volc, grid=grid, method='polyharmonic',k=2)
st <- ipol(volc, grid=grid, method='stalker',k=NA)
ml <- ipol(volc, grid=grid, method='multilinear')
g <- list(x=seq(1,nrow(volc), len=71), y=seq(1,ncol(volc),len=71))
par(mar=rep(0,4)); col <- 'green'
light <- list(specular=0.2,ambient=0.0,diffuse=0.6)
plot3D::persp3D(grid$x, grid$y, volc, colvar=NULL, lighting=light,
        theta=45, ltheta=0, lphi=40, col=col, axes=FALSE, bty='n',scale=FALSE)
for(f in list(ml, st, ph)) {
  plot3D::persp3D(g$x, g$y, evalongridV(f,grid=g), colvar=NULL, lighting=light,
        theta=45, ltheta=0, lphi=40, col=col, axes=FALSE, bty='n', scale=FALSE)
}
@ 

Then we interpolate some random points in figure~\ref{fig:random}. Incidentally, there are some
plane areas, and some torsion. Torsion is a problem for the stalker spline, the degree in one dimension
goes down to 1, creating striped artefacts in some regions. This is
alleviated by using a constant degree.  The hyperbolic stalker is 
much better.
There is no advanced
shading in \code{plot3D::persp3D}, so the \(100\times 100\) resolution
can be seen if you zoom in.

<<random, fig.dim=c(3.5,3.5), fig.pos='!ht', fig.align='center',fig.cap='Random surface',out.width='.4\\linewidth',fig.ncol=2,fig.subcap=c('stalker', 'thin plate spline','hyperbolic stalker','Floater-Hormann')>>=
set.seed(42); N <- 8
grid <- list(x=seq(0,1,length=N)+c(0,rnorm(N-2,sd=0.3/N),0), 
             y=seq(0,1,length=N)+c(0,rnorm(N-2,sd=0.3/N),0))
val <- matrix(runif(N*N,0,0.3),N)
st <- ipol(val,grid=grid, method='stalker',k=NA)
ph <- ipol(val,grid=grid, method='polyharmonic', k=2)
fh <- ipol(val,grid=grid, method='fh', k=0)
hst <- ipol(val,grid=grid, method='hstalker')
g <- list(x=seq(0,1, len=70), y=seq(0,1,len=70))
par(mar=rep(0,4))
for(f in list(st, ph, hst, fh)) {
  plot3D::persp3D(g$x, g$y, evalongridV(f,grid=g), colvar=NULL, lighting=light,
         theta=60, ltheta=30, lphi=45, col='green', axes=FALSE, bty='n', scale=FALSE,zlim=c(0,1))
  pts <- evalongridV(f,grid=grid)+0.00
  plot3D::points3D(rep(grid$x,N),rep(grid$y,each=N),pts,add=TRUE,colvar=NULL,pch=20)
}
@ 


\section{Summary}
The stalker spline is created and used with
<<eval=FALSE>>=
st <- ipol(val,grid=grid,method='stalker',k=1.5)
st(x,degree=1.2,blend='linear')
@ 
where \(k\) is the degree. \code{k} can be a vector, one degree for each
dimension. It is possible to specify any nonzero degree, though I see no use for
degrees less than 1 other than for artful displays.
Specifying \code{k=NA} makes the spline adjust the
degree locally as described above. 

Alternatively, one may create a hyperbolic stalker as
<<eval=FALSE>>=
st <- ipol(val,grid=grid,method='hstalker')
@ 
The varying degree stalker do not generalize
very well to two or more dimensions,
so for multidimenional data varying degree is strongly discouraged, except
possibly in the first dimension.
Evaluation on a non-uniform grid currently involves solving a non-linear equation
numerically, so this is slower than on a uniform grid.

The stalker spline is created with a default degree, be it \code{NA} or a numeric between 1 and 2.
It is possible at evaluation time to use a different degree, this incurs a time penalty.
Ordinarily, basis functions are combined linearly. I.e.\ when we approach a grid point more and
more of the basis function living there is weighted in. This can be changed at evaluation
time, it can be done ``faster'' with
a sigmoid map, i.e. so that near a grid point, the neighbouring basis functions are not used at all.
Use \code{blend="sigmoid"} or \code{blend="cubic"} to choose between two such sigmoid maps.

\end{document}
